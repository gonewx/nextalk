"""
FunASRæ¨¡å‹æ¨¡å—

æä¾›å…¨å±€å•ä¾‹FunASRæ¨¡å‹ç®¡ç†ï¼ŒæŒ‰ç…§å®˜æ–¹ç¤ºä¾‹çš„æ–¹å¼è¿›è¡Œæ¨¡å‹ç®¡ç†ã€‚
"""

import logging
import time
import numpy as np
from typing import Dict, Any, Optional

# ä½¿ç”¨å…¨å±€æ—¥å¿—é…ç½®
logger = logging.getLogger("nextalk_server.funasr_model")

# æ£€æŸ¥FunASRæ˜¯å¦å¯ç”¨
try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
except ImportError:
    logger.warning("FunASRæ¨¡å—ä¸å¯ç”¨ï¼Œè¯·å®‰è£…FunASRä¾èµ–")
    FUNASR_AVAILABLE = False


class GlobalFunASRModels:
    """å…¨å±€å•ä¾‹FunASRæ¨¡å‹ç®¡ç†ç±»ï¼ŒæŒ‰ç…§å®˜æ–¹ç¤ºä¾‹çš„å…¨å±€å˜é‡æ–¹å¼ç®¡ç†æ¨¡å‹"""
    
    _instance: Optional['GlobalFunASRModels'] = None
    _initialized = False
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–å…¨å±€æ¨¡å‹å˜é‡"""
        if not hasattr(self, 'model_asr'):
            # å…¨å±€æ¨¡å‹å˜é‡ï¼ˆæŒ‰å®˜æ–¹ç¤ºä¾‹å‘½åï¼‰
            self.model_asr: Optional[AutoModel] = None
            self.model_asr_streaming: Optional[AutoModel] = None
            self.model_vad: Optional[AutoModel] = None
            self.model_punc: Optional[AutoModel] = None
            
            logger.debug("åˆå§‹åŒ–å…¨å±€FunASRæ¨¡å‹å˜é‡")
    
    def initialize(self, config):
        """åŒæ­¥åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹ï¼ˆæŒ‰å®˜æ–¹ç¤ºä¾‹æ–¹å¼ï¼‰"""
        if self._initialized:
            logger.info("æ¨¡å‹å·²åˆå§‹åŒ–ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return
            
        try:
            logger.info("model loading")
            start_time = time.time()
            
            if not FUNASR_AVAILABLE:
                raise ImportError("FunASRä¸å¯ç”¨ï¼Œè¯·å®‰è£…FunASRä¾èµ–")
            
            # æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹çš„æ–¹å¼åŠ è½½æ¨¡å‹
            # ASR ç¦»çº¿æ¨¡å‹
            self.model_asr = AutoModel(
                model=getattr(config, 'asr_model', 'iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch'),
                ngpu=getattr(config, 'ngpu', 1),
                ncpu=getattr(config, 'ncpu', 4),
                device=getattr(config, 'device', 'cuda'),
                disable_pbar=True,
                disable_log=True,
            )
            
            # ASR åœ¨çº¿æ¨¡å‹  
            self.model_asr_streaming = AutoModel(
                model=getattr(config, 'asr_model_online', 'iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online'),
                ngpu=getattr(config, 'ngpu', 1),
                ncpu=getattr(config, 'ncpu', 4),
                device=getattr(config, 'device', 'cuda'),
                disable_pbar=True,
                disable_log=True,
            )
            
            # VAD æ¨¡å‹ - æ·»åŠ VADä¼˜åŒ–å‚æ•°
            vad_kwargs = {
                "max_start_silence_time": getattr(config, 'vad_max_start_silence_time', 500),
                "lookback_time_start_point": getattr(config, 'vad_lookback_time_start_point', 600), 
                "sil_to_speech_time_thres": getattr(config, 'vad_sil_to_speech_time', 80),
                "speech_to_sil_time_thres": getattr(config, 'vad_speech_to_sil_time', 150),
                "max_end_silence_time": getattr(config, 'vad_max_end_silence_time', 800),
                "speech_noise_thres": getattr(config, 'vad_speech_noise_thres', 0.4),
            }
            
            logger.info(f"ğŸ›ï¸  VADä¼˜åŒ–å‚æ•°: {vad_kwargs}")
            
            self.model_vad = AutoModel(
                model=getattr(config, 'vad_model', 'iic/speech_fsmn_vad_zh-cn-16k-common-pytorch'),
                vad_kwargs=vad_kwargs,
                ngpu=getattr(config, 'ngpu', 1),
                ncpu=getattr(config, 'ncpu', 4),
                device=getattr(config, 'device', 'cuda'),
                disable_pbar=True,
                disable_log=True,
            )
            
            # æ ‡ç‚¹æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
            punc_model_path = getattr(config, 'punc_model', 'iic/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727')
            if punc_model_path and punc_model_path.strip() != "":
                self.model_punc = AutoModel(
                    model=punc_model_path,
                    ngpu=getattr(config, 'ngpu', 1),
                    ncpu=getattr(config, 'ncpu', 4),
                    device=getattr(config, 'device', 'cuda'),
                    disable_pbar=True,
                    disable_log=True,
                )
            else:
                self.model_punc = None
            
            self._initialized = True
            duration = time.time() - start_time
            logger.info(f"model loaded! åˆå§‹åŒ–è€—æ—¶: {duration:.2f}ç§’")
            logger.info("only support one client at the same time now!!!!")
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self._initialized = False
            raise
    
    def is_initialized(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åˆå§‹åŒ–"""
        return self._initialized


# å®Œå…¨æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹å®ç°VADå‡½æ•°
async def async_vad(websocket, audio_in):
    """VADå¤„ç† - å®Œå…¨æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹å®ç°"""
    models = GlobalFunASRModels()
    if not models.is_initialized():
        raise RuntimeError("æ¨¡å‹å°šæœªåˆå§‹åŒ–")
    
    # è°ƒè¯•ï¼šè®°å½•VADè¾“å…¥
    audio_len_ms = len(audio_in) // 32  # 16kHz, 16-bit = 32 bytes per ms
    logger.debug(f"ğŸ™ï¸  VADå¤„ç†: {len(audio_in)}å­—èŠ‚ ({audio_len_ms}ms)")
    
    # æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹ï¼šä½¿ç”¨websocket.status_dict_vadå‚æ•°
    segments_result = models.model_vad.generate(input=audio_in, **websocket.status_dict_vad)[0]["value"]
    logger.debug(f"ğŸ™ï¸  VADåŸå§‹ç»“æœ: {segments_result}")

    speech_start = -1
    speech_end = -1

    # æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹ï¼šåªå¤„ç†å•ä¸ªè¯­éŸ³æ®µï¼Œå¤šæ®µæˆ–ç©ºç»“æœç›´æ¥è¿”å›-1,-1
    if len(segments_result) == 0 or len(segments_result) > 1:
        logger.debug(f"ğŸ”‡ VADè·³è¿‡: æ£€æµ‹åˆ°{len(segments_result)}ä¸ªè¯­éŸ³æ®µ")
        return speech_start, speech_end
    
    # æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹ï¼šå¤„ç†å•ä¸ªè¯­éŸ³æ®µ
    if segments_result[0][0] != -1:
        speech_start = segments_result[0][0]
        logger.info(f"ğŸ¤ VADæ£€æµ‹è¯­éŸ³å¼€å§‹: {speech_start}ms")
    if segments_result[0][1] != -1:
        speech_end = segments_result[0][1]  
        logger.info(f"ğŸ¤ VADæ£€æµ‹è¯­éŸ³ç»“æŸ: {speech_end}ms")
        
    return speech_start, speech_end


async def async_asr(websocket, audio_in):
    """ç›´æ¥ç§»æ¤å®˜æ–¹çš„async_asrå‡½æ•°ï¼Œæ·»åŠ è°ƒè¯•æ—¥å¿—"""
    models = GlobalFunASRModels()
    if not models.is_initialized():
        raise RuntimeError("æ¨¡å‹å°šæœªåˆå§‹åŒ–")
    
    # è°ƒè¯•ï¼šè®°å½•ç¦»çº¿ASRè¾“å…¥
    audio_len_ms = len(audio_in) // 32 if len(audio_in) > 0 else 0
    logger.debug(f"ğŸ¯ ASRç¦»çº¿å¤„ç†: {len(audio_in)}å­—èŠ‚ ({audio_len_ms}ms)")
        
    if len(audio_in) > 0:
        rec_result = models.model_asr.generate(input=audio_in, **websocket.status_dict_asr)[0]
        
        # è°ƒè¯•ï¼šè®°å½•åŸå§‹è¯†åˆ«ç»“æœ
        raw_text = rec_result.get("text", "")
        logger.debug(f"ğŸ“ ASRç¦»çº¿åŸå§‹ç»“æœ: '{raw_text}'")
        
        if models.model_punc is not None and len(rec_result["text"]) > 0:
            rec_result = models.model_punc.generate(
                input=rec_result["text"], **websocket.status_dict_punc
            )[0]
            logger.debug(f"ğŸ“ ASRç¦»çº¿æ ‡ç‚¹åç»“æœ: '{rec_result.get('text', '')}'")
            
        if len(rec_result["text"]) > 0:
            mode = "2pass-offline" if "2pass" in websocket.mode else websocket.mode
            message = {
                "mode": mode,
                "text": rec_result["text"],
                "wav_name": getattr(websocket, 'wav_name', 'microphone'),
                "is_final": not websocket.is_speaking,
            }
            
            # æ·»åŠ åè®®è¦æ±‚çš„å¯é€‰å­—æ®µ
            if "timestamp" in rec_result:
                message["timestamp"] = rec_result["timestamp"]
            if "stamp_sents" in rec_result:
                message["stamp_sents"] = rec_result["stamp_sents"]
            
            logger.info(f"ğŸ“¤ å‘é€ç¦»çº¿ç»“æœ: {mode} - '{rec_result['text']}'")
            import json
            await websocket.send_text(json.dumps(message))
        else:
            logger.debug(f"ğŸ¤ ASRç¦»çº¿æ— ç»“æœè¾“å‡º")
    else:
        logger.debug(f"âŒ ASRç¦»çº¿æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®")
        mode = "2pass-offline" if "2pass" in websocket.mode else websocket.mode
        message = {
            "mode": mode,
            "text": "",
            "wav_name": websocket.wav_name,
            "is_final": not websocket.is_speaking,
        }
        
        import json
        await websocket.send_text(json.dumps(message))    


async def async_asr_online(websocket, audio_in):
    """ç›´æ¥ç§»æ¤å®˜æ–¹çš„async_asr_onlineå‡½æ•°ï¼Œæ·»åŠ è°ƒè¯•æ—¥å¿—"""
    models = GlobalFunASRModels()
    if not models.is_initialized():
        raise RuntimeError("æ¨¡å‹å°šæœªåˆå§‹åŒ–")
    
    # è°ƒè¯•ï¼šè®°å½•åœ¨çº¿ASRè¾“å…¥
    audio_len_ms = len(audio_in) // 32 if len(audio_in) > 0 else 0
    is_final = websocket.status_dict_asr_online.get("is_final", False)
    logger.debug(f"âš¡ ASRåœ¨çº¿å¤„ç†: {len(audio_in)}å­—èŠ‚ ({audio_len_ms}ms) is_final={is_final}")
        
    if len(audio_in) > 0:
        rec_result = models.model_asr_streaming.generate(
            input=audio_in, **websocket.status_dict_asr_online
        )[0]
        
        # è°ƒè¯•ï¼šè®°å½•æµå¼è¯†åˆ«çŠ¶æ€
        raw_text = rec_result.get("text", "")
        logger.debug(f"âš¡ ASRåœ¨çº¿åŸå§‹ç»“æœ: '{raw_text}'")
        
        if websocket.mode == "2pass" and websocket.status_dict_asr_online.get("is_final", False):
            logger.debug(f"âš¡ ASRåœ¨çº¿è·³è¿‡æœ€ç»ˆç»“æœï¼ˆ2passæ¨¡å¼ï¼‰")
            return
            
        if len(rec_result["text"]):
            mode = "2pass-online" if "2pass" in websocket.mode else websocket.mode
            message = {
                "mode": mode,
                "text": rec_result["text"],
                "wav_name": websocket.wav_name,
                "is_final": not websocket.is_speaking,
            }
            
            logger.info(f"ğŸ“¤ å‘é€åœ¨çº¿ç»“æœ: {mode} - '{rec_result['text']}'")
            import json
            await websocket.send_text(json.dumps(message))
        else:
            logger.debug(f"ğŸ¤ ASRåœ¨çº¿æ— ç»“æœè¾“å‡º")
    else:
        logger.debug(f"âŒ ASRåœ¨çº¿æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®")