# Story 2.5: éŸ³é¢‘-æ¨ç†æµæ°´çº¿ (Audio-Inference Pipeline)

Status: done

## Prerequisites

> **å‰ç½®æ¡ä»¶**: Story 2-1 ~ 2-4 å¿…é¡»å®Œæˆ
> - âœ… Flutter Linux æ„å»ºç³»ç»Ÿå·²é…ç½® (Story 2-1)
> - âœ… PortAudio FFI ç»‘å®šå·²å®Œæˆï¼ŒAudioCapture å·²å®ç° (Story 2-2)
> - âœ… Sherpa-onnx FFI ç»‘å®šå·²å®Œæˆï¼ŒSherpaService å·²å®ç° (Story 2-3)
> - âœ… ModelManager å·²å®ç°ï¼Œå¯è·å–æ¨¡å‹è·¯å¾„ (Story 2-4)
> - âš ï¸ æœ¬ Story å®Œæˆåï¼Œå¯é€šè¿‡ `AudioInferencePipeline` è·å–å®æ—¶è¯†åˆ«ç»“æœæµ

## Story

As a **ç”¨æˆ·**,
I want **è¯´è¯æ—¶å®æ—¶çœ‹åˆ°è¯†åˆ«å‡ºçš„æ–‡å­—**,
So that **è·å¾—å³æ—¶çš„è§†è§‰åé¦ˆ**ã€‚

## Acceptance Criteria

| AC | æè¿° | éªŒè¯æ–¹æ³• |
|----|------|----------|
| AC1 | æµæ°´çº¿å¯åŠ¨: è°ƒç”¨ `Pipeline.start()` æˆåŠŸåˆå§‹åŒ–éŸ³é¢‘é‡‡é›†å’Œè¯†åˆ«å¼•æ“ | è°ƒç”¨åæ— å¼‚å¸¸ï¼Œ`isRunning` è¿”å› true |
| AC2 | é›¶æ‹·è´æ•°æ®æµ: éŸ³é¢‘æ•°æ®ä½¿ç”¨åŒä¸€å†…å­˜æŒ‡é’ˆä» PortAudio ä¼ é€’åˆ° Sherpa | æ£€æŸ¥ä»£ç ä½¿ç”¨ `AudioCapture.buffer` ç›´æ¥ä¼ ç»™ `acceptWaveform` |
| AC3 | å®æ—¶è¯†åˆ«: æ¯ 100ms éŸ³é¢‘å—è‡ªåŠ¨é€å…¥ Sherpa å¼•æ“å¹¶è§£ç  | å½•éŸ³æ—¶è§‚å¯Ÿè¯†åˆ«ç»“æœ Stream æŒç»­è¾“å‡º |
| AC4 | Stream è¾“å‡º: è¯†åˆ«ç»“æœé€šè¿‡ `Stream<String>` å®æ—¶è¾“å‡º | è®¢é˜… `resultStream` å¹¶éªŒè¯æ”¶åˆ°æ–‡æœ¬äº‹ä»¶ |
| AC5 | å»¶è¿Ÿè¦æ±‚: ç«¯åˆ°ç«¯å»¶è¿Ÿ < 200ms (NFR1) | æµ‹é‡è¯´è¯åˆ°æ–‡å­—æ˜¾ç¤ºçš„æ—¶é—´å·® |
| AC6 | æµæ°´çº¿åœæ­¢: è°ƒç”¨ `Pipeline.stop()` åœæ­¢é‡‡é›†ï¼Œè¿”å›æœ€ç»ˆç»“æœ | è°ƒç”¨å `isRunning` è¿”å› falseï¼Œèµ„æºå·²é‡Šæ”¾ |
| AC7 | é”™è¯¯å¤„ç†: éŸ³é¢‘è®¾å¤‡å¼‚å¸¸æˆ–æ¨¡å‹åŠ è½½å¤±è´¥æ—¶è¿”å›æ˜ç¡®é”™è¯¯ | æ¨¡æ‹Ÿè®¾å¤‡ä¸å¯ç”¨ï¼Œæ£€æŸ¥é”™è¯¯å›è°ƒè§¦å‘ |
| AC8 | èµ„æºé‡Šæ”¾: è°ƒç”¨ `dispose()` é‡Šæ”¾æ‰€æœ‰åŸç”Ÿèµ„æºå’Œ Stream | è°ƒç”¨åæ— å†…å­˜æ³„æ¼ï¼ŒStreamController å·²å…³é—­ |

## å¼€å§‹å‰ç¡®è®¤

```bash
# æ‰§è¡Œä»¥ä¸‹æ£€æŸ¥ï¼Œå…¨éƒ¨é€šè¿‡åæ–¹å¯å¼€å§‹
[ ] flutter test test/sherpa_service_test.dart     # SherpaService æµ‹è¯•é€šè¿‡
[ ] flutter test test/audio_capture_test.dart      # AudioCapture æµ‹è¯•é€šè¿‡
[ ] flutter test test/model_manager_test.dart      # ModelManager æµ‹è¯•é€šè¿‡
[ ] ls -la ~/.local/share/nextalk/models/*/        # æ¨¡å‹æ–‡ä»¶å­˜åœ¨
```

## æŠ€æœ¯è§„æ ¼

### æ ¸å¿ƒæ¶æ„å›¾ [Source: docs/architecture.md#4.2]

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AudioInferencePipeline                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ AudioCapture â”‚    â”‚ SharedBuffer  â”‚    â”‚   SherpaService      â”‚  â”‚
â”‚  â”‚              â”‚â”€â”€â”€â–¶â”‚ Pointer<Float>â”‚â”€â”€â”€â–¶â”‚                      â”‚  â”‚
â”‚  â”‚ Pa_ReadStreamâ”‚    â”‚  (é›¶æ‹·è´)     â”‚    â”‚ acceptWaveform()     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ decode()             â”‚  â”‚
â”‚                                           â”‚ getResult()          â”‚  â”‚
â”‚                                           â”‚ isEndpoint() â†â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”‚â”€â”€ Story 2-6 éœ€è¦
â”‚                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                      â”‚               â”‚
â”‚                                                      â–¼               â”‚
â”‚                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                                           â”‚ StreamController     â”‚  â”‚
â”‚                                           â”‚   resultStream       â”‚â”€â”€â”¼â”€â”€â–¶ UI
â”‚                                           â”‚   stateStream        â”‚â”€â”€â”¼â”€â”€â–¶ çŠ¶æ€ç›‘å¬
â”‚                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æµæ°´çº¿å¾ªç¯å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `chunkDuration` | 100ms | æ¯æ¬¡è¯»å–çš„éŸ³é¢‘æ—¶é•¿ |
| `chunkSamples` | 1600 | 16kHz Ã— 0.1s = 1600 samples |
| `sampleRate` | 16000 | å›ºå®šé‡‡æ ·ç‡ |
| `bufferFormat` | Float32 | PCM æµ®ç‚¹æ ¼å¼ï¼Œå€¼åŸŸ [-1.0, 1.0] |

### ç»„ä»¶ä¾èµ–è¡¨

| ç»„ä»¶ | æ–‡ä»¶è·¯å¾„ | å…³é”®æ¥å£ |
|------|----------|----------|
| AudioCapture | `lib/services/audio_capture.dart` | `start()`, `read(buffer, samples)` â†’ int, `stop()`, `dispose()`, `buffer`, `lastReadError` |
| SherpaService | `lib/services/sherpa_service.dart` | `initialize(config)`, `acceptWaveform(rate, ptr, n)`, `decode()`, `isReady()`, `getResult()` â†’ SherpaResult, `isEndpoint()`, `inputFinished()`, `reset()`, `dispose()` |
| ModelManager | `lib/services/model_manager.dart` | `modelPath`, `isModelReady` |

### ç›®æ ‡æ–‡ä»¶ç»“æ„

```text
voice_capsule/lib/services/
â”œâ”€â”€ audio_capture.dart       # âœ… å·²å­˜åœ¨ (Story 2-2)
â”œâ”€â”€ sherpa_service.dart      # âœ… å·²å­˜åœ¨ (Story 2-3)
â”œâ”€â”€ model_manager.dart       # âœ… å·²å­˜åœ¨ (Story 2-4)
â””â”€â”€ audio_inference_pipeline.dart  # ğŸ†• æœ¬ Story æ–°å¢
```

## Tasks / Subtasks

> **æ‰§è¡Œé¡ºåº**: Task 1 â†’ Task 2 â†’ Task 3 â†’ Task 4 â†’ Task 5 â†’ Task 6

- [x] **Task 1: åˆ›å»º AudioInferencePipeline ç±»éª¨æ¶** (AC: #1, #8)
  - [x] 1.1 åˆ›å»º `voice_capsule/lib/services/audio_inference_pipeline.dart`
  - [x] 1.2 å®šä¹‰ `PipelineState` æšä¸¾: `idle`, `initializing`, `running`, `stopping`, `error`
  - [x] 1.3 å®šä¹‰ `PipelineError` æšä¸¾: `none`, `audioInitFailed`, `modelNotReady`, `recognizerFailed`, `deviceUnavailable`
  - [x] 1.4 å®šä¹‰æ ¸å¿ƒç±»ç»“æ„ (ä½¿ç”¨æ„é€ å‡½æ•°æ³¨å…¥ä¾èµ–):
    ```dart
    class AudioInferencePipeline {
      // === ä¾èµ–æ³¨å…¥ (é€šè¿‡æ„é€ å‡½æ•°ä¼ å…¥ï¼Œä¾¿äºæµ‹è¯•) ===
      final AudioCapture _audioCapture;
      final SherpaService _sherpaService;
      final ModelManager _modelManager;

      // === é…ç½®é€‰é¡¹ ===
      final bool enableDebugLog;

      // === çŠ¶æ€ç®¡ç† ===
      final StreamController<String> _resultController = StreamController.broadcast();
      final StreamController<PipelineState> _stateController = StreamController.broadcast();
      PipelineState _state = PipelineState.idle;
      PipelineError _lastError = PipelineError.none;
      bool _stopRequested = false;
      String _lastEmittedText = '';  // ç”¨äºå»é‡

      // === æ„é€ å‡½æ•° ===
      AudioInferencePipeline({
        required AudioCapture audioCapture,
        required SherpaService sherpaService,
        required ModelManager modelManager,
        this.enableDebugLog = false,
      })  : _audioCapture = audioCapture,
            _sherpaService = sherpaService,
            _modelManager = modelManager;

      // === å…¬å¼€æ¥å£ ===
      Stream<String> get resultStream => _resultController.stream;
      Stream<PipelineState> get stateStream => _stateController.stream;
      bool get isRunning => _state == PipelineState.running;
      PipelineState get state => _state;
      PipelineError get lastError => _lastError;
    }
    ```

- [x] **Task 2: å®ç° start() åˆå§‹åŒ–æµç¨‹** (AC: #1, #7)
  - [x] 2.1 æ£€æŸ¥æ¨¡å‹å°±ç»ªçŠ¶æ€:
    ```dart
    if (!_modelManager.isModelReady) {
      _setError(PipelineError.modelNotReady);
      return _lastError;
    }
    ```
  - [x] 2.2 åˆå§‹åŒ– SherpaService (å®Œæ•´é…ç½®):
    ```dart
    final config = SherpaConfig(
      modelDir: _modelManager.modelPath,
      numThreads: 2,
      sampleRate: 16000,
      enableEndpoint: true,  // ä¸º Story 2-6 VAD å‡†å¤‡
      rule1MinTrailingSilence: 2.4,
      rule2MinTrailingSilence: 1.2,
      rule3MinUtteranceLength: 20.0,
    );
    final sherpaError = await _sherpaService.initialize(config);
    if (sherpaError != SherpaError.none) {
      _setError(PipelineError.recognizerFailed);
      return _lastError;
    }
    ```
  - [x] 2.3 å¯åŠ¨ AudioCapture:
    ```dart
    final audioError = await _audioCapture.start();
    if (audioError != AudioCaptureError.none) {
      _setError(PipelineError.audioInitFailed);
      return _lastError;
    }
    ```
  - [x] 2.4 æ›´æ–°çŠ¶æ€å¹¶å¯åŠ¨é‡‡é›†å¾ªç¯:
    ```dart
    _setState(PipelineState.running);
    _startCaptureLoop();  // ä¸ awaitï¼Œåå°è¿è¡Œ
    return PipelineError.none;
    ```

- [x] **Task 3: å®ç°é‡‡é›†-æ¨ç†å¾ªç¯ (é›¶æ‹·è´ + åŠ¨æ€è°ƒåº¦)** (AC: #2, #3, #4, #5)
  - [x] 3.1 åˆ›å»º `_startCaptureLoop()` æ–¹æ³•ï¼Œä½¿ç”¨ **async while å¾ªç¯** (ç¦æ­¢ Timer.periodic):
    ```dart
    Future<void> _startCaptureLoop() async {
      final stopwatch = Stopwatch();
      const targetDuration = Duration(milliseconds: 100);

      while (!_stopRequested && _state == PipelineState.running) {
        stopwatch.reset();
        stopwatch.start();

        await _processSingleChunk();

        stopwatch.stop();

        // æ€§èƒ½ç›‘æ§: è®°å½•è¶…è¿‡é˜ˆå€¼çš„æƒ…å†µ
        if (enableDebugLog && stopwatch.elapsedMilliseconds > 20) {
          print('[Pipeline] å¤„ç†è€—æ—¶: ${stopwatch.elapsedMilliseconds}ms');
        }

        // åŠ¨æ€è°ƒåº¦: æ ¹æ®å®é™…å¤„ç†æ—¶é—´è°ƒæ•´ç­‰å¾…æ—¶é—´
        final elapsed = stopwatch.elapsed;
        if (elapsed < targetDuration) {
          await Future.delayed(targetDuration - elapsed);
        }
        // å¦‚æœå¤„ç†æ—¶é—´è¶…è¿‡ 100msï¼Œç«‹å³è¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯ (ä¸ç­‰å¾…)
      }
    }
    ```
  - [x] 3.2 å®ç° `_processSingleChunk()` æ–¹æ³• (é›¶æ‹·è´ + æ­£ç¡®é”™è¯¯å¤„ç†):
    ```dart
    Future<void> _processSingleChunk() async {
      // é›¶æ‹·è´: ç›´æ¥ä½¿ç”¨ AudioCapture çš„å†…éƒ¨ç¼“å†²åŒº
      final buffer = _audioCapture.buffer;
      final samplesRead = _audioCapture.read(buffer, AudioConfig.framesPerBuffer);

      // é”™è¯¯æ£€æŸ¥: read() è¿”å› -1 è¡¨ç¤ºé”™è¯¯
      if (samplesRead == -1) {
        final error = _audioCapture.lastReadError;
        if (error == AudioCaptureError.deviceUnavailable) {
          _setError(PipelineError.deviceUnavailable);
          _stopRequested = true;  // è§¦å‘å¾ªç¯é€€å‡º
        }
        return;
      }

      if (samplesRead > 0) {
        // åŒä¸€æŒ‡é’ˆä¼ ç»™ Sherpa (é›¶æ‹·è´)
        _sherpaService.acceptWaveform(AudioConfig.sampleRate, buffer, samplesRead);

        // è§£ç å¹¶è·å–ç»“æœ (ä»…å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶)
        while (_sherpaService.isReady()) {
          _sherpaService.decode();
        }

        final result = _sherpaService.getResult();

        // å»é‡: åªåœ¨æ–‡æœ¬å˜åŒ–æ—¶å‘é€äº‹ä»¶
        if (result.text.isNotEmpty && result.text != _lastEmittedText) {
          _lastEmittedText = result.text;
          _resultController.add(result.text);
        }
      }
    }
    ```
  - [x] 3.3 è¾…åŠ©æ–¹æ³•å®ç°:
    ```dart
    void _setState(PipelineState newState) {
      if (_state != newState) {
        _state = newState;
        _stateController.add(newState);
      }
    }

    void _setError(PipelineError error) {
      _lastError = error;
      _setState(PipelineState.error);
    }
    ```

- [x] **Task 4: å®ç° stop() æ–¹æ³•** (AC: #6)
  - [x] 4.1 å®ç°åœæ­¢é€»è¾‘:
    ```dart
    Future<String> stop() async {
      if (_state != PipelineState.running) {
        return _lastEmittedText;
      }

      _setState(PipelineState.stopping);
      _stopRequested = true;

      // ç­‰å¾…å¾ªç¯é€€å‡º (æœ€å¤šç­‰å¾… 200ms)
      await Future.delayed(const Duration(milliseconds: 200));

      // è·å–æœ€ç»ˆè¯†åˆ«ç»“æœ
      _sherpaService.inputFinished();
      while (_sherpaService.isReady()) {
        _sherpaService.decode();
      }
      final finalResult = _sherpaService.getResult();

      // åœæ­¢éŸ³é¢‘é‡‡é›†
      await _audioCapture.stop();

      // é‡ç½® Sherpa æµçŠ¶æ€ (ä¿ç•™æ¨¡å‹ï¼Œåªæ¸…ç©ºç¼“å†²åŒº)
      _sherpaService.reset();

      // é‡ç½®çŠ¶æ€
      _stopRequested = false;
      _lastEmittedText = '';
      _setState(PipelineState.idle);

      return finalResult.text;
    }
    ```

- [x] **Task 5: å®ç° dispose() èµ„æºé‡Šæ”¾** (AC: #8)
  - [x] 5.1 å®ç°å®Œæ•´èµ„æºé‡Šæ”¾:
    ```dart
    Future<void> dispose() async {
      // 1. å¦‚æœæ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢
      if (_state == PipelineState.running) {
        await stop();
      }

      // 2. å…³é—­ StreamController
      await _resultController.close();
      await _stateController.close();

      // 3. é‡Šæ”¾åŸç”Ÿèµ„æº
      _audioCapture.dispose();
      _sherpaService.dispose();

      // 4. æ ‡è®°çŠ¶æ€ (é˜²æ­¢é‡å¤è°ƒç”¨)
      _state = PipelineState.idle;
    }
    ```

- [x] **Task 6: åˆ›å»ºå•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•** (AC: #1-8)
  - [x] 6.1 åˆ›å»º `voice_capsule/test/audio_inference_pipeline_test.dart`
  - [x] 6.2 æµ‹è¯•ç”¨ä¾‹:
    - `start()` æˆåŠŸå `isRunning` ä¸º trueï¼Œ`stateStream` å‘å‡º `running`
    - æ¨¡å‹æœªå°±ç»ªæ—¶ `start()` è¿”å› `modelNotReady` é”™è¯¯
    - éŸ³é¢‘è®¾å¤‡ä¸å¯ç”¨æ—¶è§¦å‘ `deviceUnavailable` é”™è¯¯
    - `resultStream` åœ¨å½•éŸ³æ—¶æœ‰æ•°æ®è¾“å‡º (é›†æˆæµ‹è¯•)
    - ç›¸åŒæ–‡æœ¬ä¸é‡å¤å‘é€ (å»é‡æµ‹è¯•)
    - `stop()` å `isRunning` ä¸º falseï¼Œè¿”å›æœ€ç»ˆæ–‡æœ¬
    - `dispose()` å StreamController å·²å…³é—­ï¼Œæ— å†…å­˜æ³„æ¼
  - [x] 6.3 è¿è¡Œæµ‹è¯•: `flutter test test/audio_inference_pipeline_test.dart`

## Dev Notes

### â›” DO NOT

| ç¦æ­¢äº‹é¡¹ | åŸå›  |
|----------|------|
| åœ¨å¾ªç¯ä¸­åˆ†é…æ–° buffer | å¿…é¡»ä½¿ç”¨ `AudioCapture.buffer` å®ç°é›¶æ‹·è´ |
| ä½¿ç”¨ `Isolate.run()` åšéŸ³é¢‘å¾ªç¯ | FFI æŒ‡é’ˆä¸èƒ½è·¨ Isolateï¼Œä¼š crash |
| ä½¿ç”¨ `Timer.periodic` å›ºå®šé—´éš” | ä¼šç´¯ç§¯å»¶è¿Ÿï¼›å¿…é¡»ç”¨ while å¾ªç¯ + Stopwatch åŠ¨æ€è°ƒåº¦ |
| å¿½ç•¥ `read()` è¿”å› -1 | è¿”å› -1 è¡¨ç¤ºé”™è¯¯ï¼Œå¿…é¡»æ£€æŸ¥ `lastReadError` |
| è·³è¿‡æ¨¡å‹å°±ç»ªæ£€æŸ¥ | `isModelReady` è¿”å› false æ—¶ä¸èƒ½åˆå§‹åŒ– Sherpa |
| åœ¨ UI çº¿ç¨‹åšé˜»å¡æ“ä½œ | `Pa_ReadStream` é˜»å¡ 100msï¼Œä½†åœ¨ async å¾ªç¯ä¸­å¯æ¥å— |
| å¿˜è®°è°ƒç”¨ `dispose()` | å¿…é¡»é‡Šæ”¾åŸç”Ÿèµ„æºï¼Œå¦åˆ™å†…å­˜æ³„æ¼ |

### æ¶æ„çº¦æŸ [Source: docs/architecture.md#4.2]

| çº¦æŸ | æè¿° |
|------|------|
| **é›¶æ‹·è´** | éŸ³é¢‘æ•°æ®å¿…é¡»ä½¿ç”¨åŒä¸€ `Pointer<Float>`ï¼Œä» PortAudio ç›´æ¥åˆ° Sherpa |
| **ä¸» Isolate** | MVP é˜¶æ®µåœ¨ä¸» Isolate è¿è¡Œï¼Œå¤„ç† 100ms å—è€—æ—¶ < 10ms å¯æ¥å— |
| **å»¶è¿Ÿé¢„ç®—** | 200ms = 100ms (é‡‡é›†) + 10ms (æ¨ç†) + 90ms (ä½™é‡) |

### ä¸ç°æœ‰ç»„ä»¶çš„æ¥å£ä¸€è‡´æ€§

| ç»„ä»¶ | æ¥å£ | ç­¾å | è¯´æ˜ |
|------|------|------|------|
| AudioCapture | `buffer` | `Pointer<Float> get buffer` | è¿”å› 1600 samples ç¼“å†²åŒº |
| AudioCapture | `read` | `int read(Pointer<Float> buffer, int samples)` | è¿”å›å®é™…è¯»å–æ•°ï¼Œ-1 è¡¨ç¤ºé”™è¯¯ |
| AudioCapture | `lastReadError` | `AudioCaptureError get lastReadError` | read() è¿”å› -1 æ—¶çš„è¯¦ç»†é”™è¯¯ |
| AudioCapture | `dispose` | `void dispose()` | é‡Šæ”¾ PortAudio èµ„æº |
| SherpaService | `acceptWaveform` | `void acceptWaveform(int rate, Pointer<Float> ptr, int n)` | é›¶æ‹·è´æ¥å—éŸ³é¢‘ |
| SherpaService | `isReady` | `bool isReady()` | æ˜¯å¦æœ‰è¶³å¤Ÿæ•°æ®è§£ç  |
| SherpaService | `decode` | `void decode()` | æ‰§è¡Œä¸€æ¬¡è§£ç  |
| SherpaService | `getResult` | `SherpaResult getResult()` | è¿”å› `SherpaResult` å¯¹è±¡ï¼Œä½¿ç”¨ `.text` è·å–æ–‡æœ¬ |
| SherpaService | `isEndpoint` | `bool isEndpoint()` | æ˜¯å¦æ£€æµ‹åˆ°ç«¯ç‚¹ (Story 2-6 ä½¿ç”¨) |
| SherpaService | `inputFinished` | `void inputFinished()` | æ ‡è®°è¾“å…¥ç»“æŸ |
| SherpaService | `reset` | `void reset()` | é‡ç½®æµçŠ¶æ€ï¼Œä¿ç•™æ¨¡å‹ |
| SherpaService | `dispose` | `void dispose()` | é‡Šæ”¾ Sherpa èµ„æº |
| ModelManager | `isModelReady` | `bool get isModelReady` | æ¨¡å‹æ˜¯å¦å°±ç»ª |
| ModelManager | `modelPath` | `String get modelPath` | æ¨¡å‹ç›®å½•å®Œæ•´è·¯å¾„ |

### SherpaConfig å®Œæ•´é…ç½®

```dart
final config = SherpaConfig(
  modelDir: _modelManager.modelPath,
  numThreads: 2,
  sampleRate: 16000,
  featureDim: 80,
  enableEndpoint: true,       // âš ï¸ å¿…é¡»ä¸º trueï¼ŒStory 2-6 VAD ä¾èµ–æ­¤é…ç½®
  rule1MinTrailingSilence: 2.4,
  rule2MinTrailingSilence: 1.2,
  rule3MinUtteranceLength: 20.0,
  decodingMethod: 'greedy_search',
  provider: 'cpu',
);
```

### å»¶è¿Ÿæµ‹é‡æ–¹æ³•

```dart
// åœ¨ _processSingleChunk() ä¸­æµ‹é‡ç«¯åˆ°ç«¯å»¶è¿Ÿ
final audioTimestamp = DateTime.now();  // éŸ³é¢‘é‡‡é›†æ—¶é—´ç‚¹
// ... å¤„ç† ...
final resultTimestamp = DateTime.now(); // ç»“æœè¾“å‡ºæ—¶é—´ç‚¹
final latency = resultTimestamp.difference(audioTimestamp);
if (latency.inMilliseconds > 200) {
  print('[WARNING] å»¶è¿Ÿè¶…æ ‡: ${latency.inMilliseconds}ms');
}
```

### å¿«é€ŸéªŒè¯è„šæœ¬

```bash
#!/bin/bash
# scripts/verify-pipeline.sh
set -e
echo "=== Story 2-5 éªŒè¯ ==="

echo "1. æ£€æŸ¥ä¾èµ–æœåŠ¡..."
cd voice_capsule
flutter test test/audio_capture_test.dart --reporter compact
flutter test test/sherpa_service_test.dart --reporter compact
flutter test test/model_manager_test.dart --reporter compact

echo "2. è¿è¡Œ Pipeline æµ‹è¯•..."
flutter test test/audio_inference_pipeline_test.dart

echo "3. æ£€æŸ¥æ–‡ä»¶åˆ›å»º..."
[ -f lib/services/audio_inference_pipeline.dart ] && echo "   âœ… Pipeline æœåŠ¡å­˜åœ¨"

echo "=== éªŒè¯å®Œæˆ ==="
```

### å¤–éƒ¨èµ„æº

- [Sherpa-onnx æµå¼è¯†åˆ«ç¤ºä¾‹](https://k2-fsa.github.io/sherpa/onnx/flutter/index.html)
- [Dart Stream æ–‡æ¡£](https://dart.dev/tutorials/language/streams)
- [Flutter æ€§èƒ½æœ€ä½³å®è·µ](https://docs.flutter.dev/perf/best-practices)

## Dev Agent Record

### Agent Model Used

Claude Opus 4.5 (claude-opus-4-5-20251101)

### Debug Log References

- ä¿®å¤äº† MockSherpaService æ— é™å¾ªç¯é—®é¢˜ï¼šæ·»åŠ  `_hasNewData` æ ‡å¿—æ­£ç¡®æ¨¡æ‹Ÿ decode è¡Œä¸º
- å®ç°äº†å¯ä¸­æ–­å»¶è¿Ÿ `_interruptibleDelay()` ç¡®ä¿å“åº”å¼åœæ­¢
- æ·»åŠ  `Completer<void>` è·Ÿè¸ªé‡‡é›†å¾ªç¯å®ŒæˆçŠ¶æ€

### Completion Notes List

1. **æ‰€æœ‰ 29 ä¸ªå•å…ƒæµ‹è¯•é€šè¿‡** - è¦†ç›– AC1-AC8 å…¨éƒ¨éªŒæ”¶æ ‡å‡† (Code Review æ–°å¢ 5 ä¸ªæµ‹è¯•)
2. **é›¶æ‹·è´å®ç°éªŒè¯** - ä½¿ç”¨ `AudioCapture.buffer` ç›´æ¥ä¼ ç»™ `acceptWaveform()`ï¼Œæ–°å¢æŒ‡é’ˆåœ°å€éªŒè¯æµ‹è¯•
3. **åŠ¨æ€è°ƒåº¦éªŒè¯** - ä½¿ç”¨ async while å¾ªç¯ + Stopwatchï¼Œé Timer.periodic
4. **èµ„æºé‡Šæ”¾éªŒè¯** - dispose() æ­£ç¡®å…³é—­ StreamController å¹¶é‡Šæ”¾åŸç”Ÿèµ„æº
5. **AC5 å»¶è¿Ÿæµ‹é‡å·²å®ç°** - æ·»åŠ  `LatencyStats` ç±»å’Œ `latencyStats` getterï¼Œè®°å½•ç«¯åˆ°ç«¯å»¶è¿Ÿ

### Change Log

- 2025-12-22: Story created by SM Agent (Bob) - YOLO æ¨¡å¼
- 2025-12-22: Story validated and enhanced by SM Agent (Bob) - ä¿®å¤ 5 ä¸ªå…³é”®é—®é¢˜ï¼Œæ·»åŠ  4 ä¸ªå¢å¼ºï¼Œ3 ä¸ªä¼˜åŒ–
- 2025-12-22: Story completed by Dev Agent (Amelia) - å®ç°å…¨éƒ¨ 6 ä¸ª Taskï¼Œ24 ä¸ªæµ‹è¯•é€šè¿‡
- 2025-12-22: **Code Review by Dev Agent (Amelia)** - å‘ç° 6 ä¸ªé—®é¢˜ï¼Œä¿®å¤ 5 ä¸ª:
  - âœ… H1: AC5 å»¶è¿Ÿæµ‹é‡æœªå®ç° â†’ æ·»åŠ  `LatencyStats` ç±»å’Œæµ‹é‡é€»è¾‘
  - âœ… H2: é›¶æ‹·è´éªŒè¯æµ‹è¯•ç¼ºå¤± â†’ æ·»åŠ æŒ‡é’ˆåœ°å€éªŒè¯æµ‹è¯•
  - âœ… M1: StreamController å…³é—­åå¯èƒ½è¢«è®¿é—® â†’ æ·»åŠ  `_isDisposed` æ£€æŸ¥
  - âœ… M3: stop() å›ºå®š 500ms è¶…æ—¶ â†’ ä¼˜åŒ–ä¸º 20ms è½®è¯¢é—´éš”
  - âš ï¸ M2: è°ƒè¯•æµ‹è¯•æ–‡ä»¶ä¿ç•™ â†’ éœ€æ‰‹åŠ¨åˆ é™¤ `pipeline_debug_test.dart`
  - âš ï¸ H3: Mock ç±»ç»§æ‰¿è®¾è®¡ â†’ é™çº§ä¸º Low (å·¥ä½œæ­£å¸¸ï¼Œè®°å½•ä¸ºæŠ€æœ¯å€ºåŠ¡)

### File List

**å·²åˆ›å»º/ä¿®æ”¹æ–‡ä»¶:**

| æ–‡ä»¶ | æ“ä½œ | è¯´æ˜ |
|------|------|------|
| `voice_capsule/lib/services/audio_inference_pipeline.dart` | ä¿®æ”¹ | éŸ³é¢‘-æ¨ç†æµæ°´çº¿æœåŠ¡ (390+ è¡Œï¼Œæ–°å¢ LatencyStats) |
| `voice_capsule/test/audio_inference_pipeline_test.dart` | ä¿®æ”¹ | å•å…ƒæµ‹è¯• (660+ è¡Œ, 29 æµ‹è¯•ï¼Œæ–°å¢ AC2/AC5 éªŒè¯) |
| `voice_capsule/test/pipeline_debug_test.dart` | âš ï¸å¾…åˆ é™¤ | è°ƒè¯•æµ‹è¯• (éœ€æ‰‹åŠ¨åˆ é™¤) |

---
*References: docs/architecture.md#4.2, docs/prd.md#FR2, _bmad-output/epics.md#Story-2.5, Story 2-2, Story 2-3, Story 2-4*
