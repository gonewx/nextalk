# NexTalk 系统架构

本文档详细描述了NexTalk的系统架构，包括主要组件、数据流、技术栈选择以及系统间交互方式。

## 1. 系统概述

NexTalk是一个轻量级实时本地语音识别和输入系统，允许用户通过语音输入文本到任何应用程序。系统由两个主要部分组成：客户端和服务器，它们通过WebSocket协议进行实时通信。

### 1.1 核心功能

- 实时语音捕获和处理
- 高质量语音识别（基于Whisper模型）
- 低延迟文本输入到活动应用程序
- 热键控制的语音识别激活/停用
- 系统托盘界面和状态指示
- 可切换的语音识别模型

### 1.2 系统架构示意图

```
+-----------------------+        WebSocket        +------------------------+
|                       |  音频数据 / 转录结果   |                        |
|    NexTalk 客户端     | <------------------->  |    NexTalk 服务器      |
|                       |                         |                        |
+-----------------------+                         +------------------------+
    |             ^                                       |          ^
    |             |                                       |          |
    v             |                                       v          |
+--------+    +--------+                          +----------+  +----------+
| 音频   |    | 文本   |                          | 语音     |  | Whisper  |
| 捕获   |    | 注入   |                          | 活动检测 |  | 模型     |
+--------+    +--------+                          +----------+  +----------+
```

## 2. 主要组件

NexTalk系统由以下主要组件组成：

### 2.1 客户端组件

1. **AudioCapturer**：负责从系统麦克风捕获音频数据。
   - 使用PyAudio库实现
   - 支持设备选择和音频参数配置
   - 通过回调函数提供音频数据

2. **WebSocketClient**：管理与服务器的WebSocket连接。
   - 发送音频数据到服务器
   - 接收转录结果和状态更新
   - 处理连接、断连和错误情况

3. **Injector**：将转录文本注入到当前活动的应用程序。
   - 平台特定实现（目前支持Linux系统）
   - 使用xdotool在Linux上实现文本输入
   - 模块化设计允许未来支持其他平台

4. **HotkeyListener**：监听全局热键事件。
   - 使用pynput监听键盘事件
   - 支持自定义热键组合
   - 提供激活/停用回调功能

5. **SystemTrayIcon**：提供系统托盘界面。
   - 显示当前状态图标
   - 提供模型选择菜单
   - 支持退出和设置选项

6. **NexTalkClient**：客户端核心逻辑类。
   - 协调所有客户端组件
   - 管理客户端状态
   - 处理来自服务器的消息
   - 实现模型切换请求功能

### 2.2 服务器组件

1. **WebSocketEndpoint**：处理WebSocket连接和消息。
   - 接收客户端的音频数据
   - 发送转录结果和状态更新
   - 处理命令消息（如模型切换）

2. **VADFilter**：语音活动检测过滤器。
   - 使用WebRTC VAD算法
   - 仅处理包含语音的音频帧
   - 可配置的灵敏度级别

3. **AudioBuffer**：音频数据缓冲区。
   - 临时存储语音帧
   - 累积足够的音频进行处理
   - 线程安全的实现

4. **ASRRecognizer**：自动语音识别处理器。
   - 集成Whisper模型
   - 处理音频数据并生成文本转录
   - 支持不同模型大小和计算设备

5. **ModelManager**：管理Whisper模型。
   - 加载和卸载模型
   - 实现模型切换功能
   - 管理模型资源

### 2.3 共享组件

1. **数据模型**：定义客户端和服务器间的通信数据结构。
   - TranscriptionResponse：转录结果响应
   - ErrorMessage：错误消息
   - StatusUpdate：状态更新消息
   - CommandMessage：命令消息

2. **常量**：定义系统中使用的常量。
   - 音频参数（采样率、通道数、帧长等）
   - 状态字符串
   - 默认设置值

## 3. 数据流

### 3.1 音频捕获和处理流程

1. 客户端通过热键激活音频捕获
2. AudioCapturer从麦克风捕获音频并传递给客户端核心
3. 客户端通过WebSocket发送音频数据到服务器
4. 服务器的VADFilter检测语音活动
5. 有语音的帧被添加到AudioBuffer中
6. 服务器周期性检查缓冲区，累积足够的音频后处理
7. ASRRecognizer使用Whisper模型转录音频
8. 转录结果通过WebSocket发送回客户端
9. 客户端接收转录文本并使用Injector注入到活动应用程序

### 3.2 模型切换流程

1. 用户从系统托盘菜单选择不同的模型
2. 客户端构建CommandMessage并发送到服务器
3. 服务器接收命令并通过ModelManager切换模型
4. 服务器返回命令执行结果
5. 客户端显示模型切换结果的通知

### 3.3 状态更新流程

1. 服务器或客户端状态变化时（如开始监听、处理中、错误等）
2. 服务器生成StatusUpdate消息并发送给客户端
3. 客户端更新内部状态和UI表示（托盘图标和通知）

## 4. 技术栈选择

### 4.1 核心技术

| 组件 | 技术选择 | 原因 |
|------|---------|------|
| 语言 | Python 3.10+ | 跨平台支持、丰富的库生态系统、快速开发 |
| 音频处理 | PyAudio | 跨平台音频捕获支持、简单API、低延迟 |
| 语音识别 | Whisper (faster-whisper) | 高质量离线语音识别、多语言支持、可选模型大小 |
| 语音活动检测 | WebRTC VAD | 高效、精确的语音检测、低资源消耗 |
| 网络通信 | WebSocket (websockets) | 全双工通信、低延迟、支持二进制数据 |
| 服务器框架 | FastAPI + Uvicorn | 高性能异步API框架、内置WebSocket支持、易于扩展 |
| 文本注入 | xdotool (Linux) | 可靠的系统级文本输入、跨应用程序支持 |
| UI界面 | pystray | 轻量级系统托盘支持、跨平台 |
| 配置管理 | ConfigParser | 标准库支持、简单易用 |
| 热键处理 | pynput | 跨平台全局热键支持、低资源消耗 |

### 4.2 依赖管理

NexTalk使用现代Python包管理工具uv进行依赖管理，配合pyproject.toml文件定义项目结构和依赖关系，提高了环境重现性和安装便利性。

## 5. 模块结构

```
nextalk/
├── src/
│   ├── nextalk_client/            # 客户端代码
│   │   ├── audio/                 # 音频捕获
│   │   ├── config/                # 客户端配置
│   │   ├── hotkey/                # 热键监听
│   │   ├── injection/             # 文本注入
│   │   ├── network/               # 网络通信
│   │   ├── ui/                    # 用户界面
│   │   ├── client_logic.py        # 客户端核心逻辑
│   │   └── main.py                # 客户端入口点
│   │
│   ├── nextalk_server/            # 服务器代码
│   │   ├── api/                   # API端点
│   │   ├── asr/                   # 语音识别
│   │   ├── audio/                 # 音频处理
│   │   ├── config/                # 服务器配置
│   │   ├── models/                # 模型管理
│   │   ├── server_app.py          # 服务器应用
│   │   └── main.py                # 服务器入口点
│   │
│   └── nextalk_shared/            # 共享组件
│       ├── constants.py           # 共享常量
│       └── data_models.py         # 共享数据模型
│
├── config/                        # 配置文件
├── docs/                          # 文档
├── scripts/                       # 运行脚本
└── tests/                         # 测试
    ├── client/                    # 客户端测试
    ├── server/                    # 服务器测试
    └── shared/                    # 共享组件测试
```

## 6. 关键技术决策

### 6.1 客户端-服务器分离架构

NexTalk采用了客户端-服务器分离架构，而不是单一应用程序架构，主要基于以下考虑：

1. **资源隔离**：语音识别模型（尤其是大型模型）需要大量内存和GPU资源，通过服务器隔离这些资源消耗
2. **功能解耦**：允许客户端专注于UI和用户交互，服务器专注于计算密集型任务
3. **灵活部署**：支持单机部署和远程服务器部署两种模式
4. **多客户端支持**：未来可以扩展支持多个客户端连接到同一服务器

### 6.2 WebSocket通信

选择WebSocket作为通信协议的原因：

1. **实时性**：提供低延迟的全双工通信
2. **二进制支持**：有效传输音频数据
3. **状态管理**：维护持久连接，简化状态同步
4. **广泛支持**：良好的库支持和跨平台兼容性

### 6.3 插件式文本注入

设计了基于平台的文本注入器抽象类和工厂模式：

1. **跨平台扩展性**：虽然当前版本主要支持Linux，但架构设计允许轻松添加其他平台支持
2. **解耦依赖**：平台特定代码被隔离在特定模块中
3. **统一接口**：所有平台实现都遵循同一接口，简化客户端逻辑

## 7. 性能考虑

### 7.1 音频处理

- 使用VAD进行语音检测，减少处理非语音数据的资源消耗
- 音频帧缓冲设计优化了内存使用和处理延迟的平衡
- 使用numpy进行高效的音频数据操作

### 7.2 语音识别

- 支持多种Whisper模型大小，从tiny到large，根据性能需求和资源可用性选择
- 支持CPU和CUDA设备选择，适应不同硬件环境
- 实现int8和float16等不同计算类型，优化性能和内存使用

### 7.3 并发处理

- 使用异步编程模型处理WebSocket通信和音频处理
- 分离音频捕获和处理线程，确保捕获不被处理延迟影响
- 实现线程安全的数据共享机制

## 8. 扩展性和未来发展

### 8.1 计划的扩展

- Windows和macOS文本注入支持
- 更多语音识别模型选项
- 高级语音命令和自定义操作
- 用户界面改进和配置面板
- 离线运行模式优化

### 8.2 扩展点

系统设计中预留了以下扩展点：

1. **插件系统**：为文本处理和命令解析添加插件架构
2. **替代模型**：支持替换Whisper为其他语音识别引擎
3. **自定义配置**：扩展配置系统，支持更多用户偏好设置
4. **分布式部署**：增强网络层，支持远程服务器集群 